---
layout: post
title: Multilingual Transfer in Automatic Summarization
subtitle: Using sequence-to-sequence architecture to perform summarization across multiple languages 
cover-img: 
thumbnail-img: 
share-img: /assets/img/path.jpg
tags: [deep learning, transformers, bert, aws, nlp]
---

The primary objective of this research was to evaluate a trained summarization model's performance over a multi-lingual dataset to generate summaries specifically  in other languages than English. Since the summarization training set is already an English to English mapping, it was established as a baseline to investigate the knowledge transfer across multiple languages(English, German and Dutch) during summary generation.
